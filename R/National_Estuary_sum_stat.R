#' Formats files downloaded from NERRS at http://cdmo.baruch.sc.edu/get/landing.cfm into AWQMS import files
#'
#' Download csv files and  save to a folder. The function will open a directory selector. Point the function to the
#' directory where the csv files are saved. AWQMS import files will be saved in the same location
#'
#' @export


NERRS_sum_stats <- function(path){


options(scipen=999)
  deployment_list <- list()

#testing
#path <- 'C:/Users/tpritch/Oregon/DEQ - Integrated Report - IR 2024/DataAssembly/NERRS/Orginal Files/'
in_fnames <- list.files(path, full.names = TRUE)
in_fnames <- in_fnames[grep("wq", in_fnames)]
in_fnames <- in_fnames[grep("csv", in_fnames)]


if(length(in_fnames) == 0){
  stop("No wq files found.")

}


for(h in 1:length(in_fnames)){

  print(paste("Starting file", h, "of",length(in_fnames) ))

  filepath = in_fnames[h]

  data_import <- read.csv(filepath, stringsAsFactors = FALSE) %>%
    dplyr::select(StationCode, DateTimeStamp, Temp, F_Temp, DO_Pct, F_DO_Pct, DO_mgl, F_DO_mgl, pH, F_pH) %>%
    dplyr::mutate(DateTimeStamp = lubridate::mdy_hm(DateTimeStamp))

  #tz(data_import$DateTimeStamp) <- "America/Los_Angeles"



  data_long <- data_import %>%
    tidyr::gather(key = 'parameter', value = 'result', -StationCode, -DateTimeStamp, -F_Temp, -F_DO_Pct, -F_DO_mgl, -F_pH ) %>%
    dplyr::mutate(qual = dplyr::case_when(parameter == "Temp"~ F_Temp,
                                          parameter == "DO_mgl" ~ F_DO_mgl,
                                          parameter == "DO_Pct" ~ F_DO_Pct,
                                          parameter == "pH" ~ F_pH,
                                          TRUE ~ "ERROR" ),
                  date = as.Date(DateTimeStamp)) %>%
    dplyr::select(-F_Temp, -F_DO_mgl, -F_DO_Pct, -F_pH) %>%
    # Filter out suspect and other bad data, keep only 0,2,3,4,and 5 labeled data
    dplyr::filter(grepl("<0>|<2>|<3>|<4>|<5>", qual)) |>
    dplyr::mutate(Equipment_ID = StationCode)


#QC CODES
  # -5	Outside high sensor range
  # -4	Outside low sensor range
  # -3	Data rejected due to QA/QC
  # -2	Missing data
  # -1	Optional parameter not collected
  # 0	Passed initial QAQC checks
  # 1	Suspect data
  # 2	Reserved for future use*
  # 3	Calculated data: non-vented depth/level sensor correction for changes in barometric pressure*
  # 4	Historical: Pre-auto QA/QC
  # 5	Corrected data


  # get unique list of characteristics to run for loop through
  unique_characteritics <- unique(data_long$parameter) |>
    str_subset("pH", negate=TRUE)


  #create list for getting data out of loop
  monloc_do_list <- list()
  sumstatlist <- list()

  # For loop for summary statistics -----------------------------------------

  # Loop goes through each characteristc and generates summary stats
  # After loop, data gets pushed inot single table
  for (i in 1:length(unique_characteritics)){

    print(paste("Begin",  unique_characteritics[i], "- characteristic", i, "of", length(unique_characteritics)))

    # Characteristic for this loop iteration
    char <- unique_characteritics[i]

    # Filter so table only contains single characteristic
    results_data_char <- data_long %>%
      dplyr::filter(parameter == char) %>%
      # generare unique hour field for hourly values and stats
      dplyr::mutate(hr =  format(DateTimeStamp, "%Y-%j-%H"))

    # Simplify to hourly values and Stats
    hrsum <- results_data_char %>%
      dplyr::group_by(StationCode, hr) %>%
      dplyr::summarise(date = mean(date),
                hrDTmin = min(DateTimeStamp),
                hrDTmax = max(DateTimeStamp),
                hrN = sum(!is.na(result)),
                hrMean = mean(result, na.rm=TRUE),
                hrMin = min(result, na.rm=TRUE),
                hrMax = max(result, na.rm=TRUE))


    # For each date, how many hours have hrN > 0
    # remove rows with zero records in an hour.
    hrdat<- hrsum[which(hrsum$hrN >0),]

    # # Summarise to daily statistics
    # daydat <- hrdat %>%
    #   dplyr::group_by(Monitoring_Location_ID, Equipment_ID, date, Result_Unit, Activity_Time_Zone, mloc_equip) %>%
    #   dplyr::summarise(dDTmin = min(hrDTmin),
    #                    dDTmax = max(hrDTmax),
    #                    hrNday = length(hrN),
    #                    dyN = sum(hrN),
    #                    dyMean =mean(hrMean, na.rm=TRUE),
    #                    dyMin = min(hrMin, na.rm=TRUE),
    #                    dyMax = max(hrMax, na.rm=TRUE)) %>%
    #   dplyr::mutate(ResultStatusID = dplyr::if_else(hrNday >= 22, 'Final', "Rejected"),
    #                 cmnt = dplyr::case_when(hrNday >= 22 ~ "Generated by ORDEQ",
    #                                         hrNday <= 22 & hrNday >= 20 ~ paste0("Generated by ORDEQ; Estimated - ", as.character(hrNday), ' hrs with valid data in day'),
    #                                         TRUE ~ paste0("Generated by ORDEQ; Rejected - ", as.character(hrNday), ' hrs with valid data in day')))
    #

    daydat <- hrdat %>%
      dplyr::group_by(StationCode, date) %>%
      dplyr::summarise(dDTmin = min(hrDTmin),
                       dDTmax = max(hrDTmax),
                       hrNday = length(hrN),
                       dyN = sum(hrN),
                       dyMean =mean(hrMean, na.rm=TRUE),
                       dyMin = min(hrMin, na.rm=TRUE),
                       dyMax = max(hrMax, na.rm=TRUE)) %>%
      dplyr::mutate(ResultStatusID = dplyr::if_else(hrNday >= 22, 'Final', "Rejected"),
                    cmnt = dplyr::case_when(hrNday >= 22 ~ "Generated by ORDEQ",
                                            hrNday <= 22 & hrNday >= 20 ~ paste0("Generated by ORDEQ; Estimated - ", as.character(hrNday), ' hrs with valid data in day'),
                                            TRUE ~ paste0("Generated by ORDEQ; Rejected - ", as.character(hrNday), ' hrs with valid data in day')))


    #Deal with DO Results
    if (grepl("DO", char)) {

      daydat_station <- daydat %>%
        dplyr::filter(hrNday >= 22) %>%
        dplyr::filter(ResultStatusID != "Rejected")


      daydat_station2 <- daydat_station %>%
        dplyr::ungroup() %>%
        dplyr::group_by(StationCode) %>%
        dplyr::mutate(row = dplyr::row_number(),
                      d = runner(x = data.frame(dyMean_run = dyMean, dyMin_run = dyMin, dDTmin_run = dDTmin,
                                                dDTmax_run = dDTmax),
                                 k = "7 days",
                                 lag = 0,
                                 idx = date,
                                 f = function(x) list(x)),
                      d30 =  runner(x = data.frame(dyMean_run = dyMean,  dDTmin_run = dDTmin,
                                                   dDTmax_run = dDTmax),
                                    k = "30 days",
                                    lag = 0,
                                    idx = date,
                                    f = function(x) list(x))) %>%
        dplyr::mutate(d = purrr::map(d, ~ .x %>%
                                       dplyr::summarise(ma.mean7 = dplyr::case_when(length(dyMean_run) >= 6 ~  mean(dyMean_run),
                                                                                    TRUE ~ NA_real_),
                                                        ma.min7 = dplyr::case_when(length(dyMin_run) >= 6 ~  mean(dyMin_run),
                                                                                   TRUE ~ NA_real_),
                                                        ana_startdate7 = min(dDTmin_run),
                                                        ana_enddate7   = max(dDTmax_run),
                                                        act_enddate7   = max(dDTmax_run))

        ))%>%
        dplyr::mutate(d30 = purrr::map(d30, ~ .x %>%
                                         dplyr::summarise(ma.mean30 = dplyr::case_when(length(dyMean_run) >= 29 ~  mean(dyMean_run),
                                                                                       TRUE ~ NA_real_),
                                                          ana_startdate30 = min(dDTmin_run),
                                                          ana_enddate30 =  max(dDTmax_run),
                                                          act_enddate30 = max(dDTmax_run))

        )) %>%
        tidyr::unnest_wider(d) %>%
        tidyr::unnest_wider(d30) %>%
        dplyr::mutate(ma.mean7 = ifelse(row < 7, NA, ma.mean7),
                      ma.min7 = ifelse(row < 7, NA, ma.min7),
                      ma.mean30 = ifelse(row < 30, NA, ma.mean30)) %>%
        dplyr::select(-row)


      # Combine list to single dataframe
      sum_stats <- daydat_station2 %>%
        dplyr::arrange(StationCode, date)


    } # end of DO if statement



    ##  TEMPERATURE

    if (char == 'Temp' ) {


      #Filter dataset to only look at 1 monitoring location at a time
      daydat_station <- daydat %>%
        dplyr::ungroup() %>%
        dplyr::group_by(StationCode) %>%
        dplyr::filter(hrNday >= 22)

      # 7 day loop
      # Loops through each row in the monitoring location dataset
      # And pulls out records that are within the preceding 7 day window
      # If there are at least 6 values, then calculate 7 day min and mean
      # Assigns data back to daydat_station
      print("Begin 7 day moving averages")


      daydat_station2 <- daydat_station %>%
        dplyr::ungroup() %>%
        dplyr::group_by(StationCode) %>%
        dplyr::mutate(row = dplyr::row_number(),
                      d = runner(x = data.frame(dyMax_run = dyMax,  dDTmin_run = dDTmin,
                                                dDTmax_run = dDTmax),
                                 k = "7 days",
                                 lag = 0,
                                 idx = date,
                                 f = function(x) list(x))) %>%
        dplyr::mutate(d = purrr::map(d, ~ .x %>%
                                       dplyr::summarise(ma.max7 = dplyr::case_when(length(dyMax_run) >= 6 ~  mean(dyMax_run),
                                                                                   TRUE ~ NA_real_
                                       ),
                                       ana_startdate7 = min(dDTmin_run),
                                       ana_enddate7 =  max(dDTmax_run),
                                       act_enddate7 = max(dDTmax_run))

        ))%>%
        tidyr::unnest_wider(d) %>%
        dplyr::mutate(ma.max7 = ifelse(row < 7, NA, ma.max7)) %>%
        dplyr::select(-row)



      # Combine list to single dataframe
      sum_stats <- daydat_station2 %>%
        dplyr::arrange(StationCode, date)




    } #end of temp if statement



    ## Other - just set sum_stats to daydat, since no moving averages need to be generated.
    if (char != 'Temp' & !grepl("DO", char) ) {

      sum_stats <- daydat

    } #end of not DO or temp statement

    #Assign the char ID to the dataset
    sum_stats <- sum_stats %>%
      dplyr::mutate(charID = char)

    #Set to list for getting out of for loop
    sumstatlist[[i]] <-  sum_stats


  } # end of characteristics for loop

  sumstat <- dplyr::bind_rows(sumstatlist)

  #Gather summary statistics from wide format into long format
  #rename summary statistcs to match AWQMS Import COnfiguration
  sumstat_long <- sumstat %>%
    dplyr::rename("Daily Maximum" = dyMax,
           "Daily Minimum" = dyMin,
           "Daily Mean"    = dyMean,
           "7DMADMin"      = ma.min7,
           "7DMADMean"     = ma.mean7,
           "7DMADMax"      = ma.max7,
           "30DMADMean"    = ma.mean30) %>%
    tidyr::gather(
      "Daily Maximum",
      "Daily Minimum",
      "Daily Mean",
      "7DMADMin",
      "7DMADMean",
      "7DMADMax",
      "30DMADMean",
      key = "StatisticalBasis",
      value = "Result",
      na.rm = TRUE
    ) %>%
    dplyr::arrange(StationCode, date) %>%
    dplyr::mutate(Equipment = "ContinuousPrb")

  AQWMS_sum_stat <- sumstat_long %>%
    dplyr::mutate(r_units = ifelse(charID == "Temp", "deg C",
                            ifelse(charID == "DO_mgl", "mg/l",
                                   ifelse(charID == "DO_Pct", "% saturatn", "ERROR" ))),
           charID = ifelse(charID == "Temp", "Temperature, water",
                           ifelse(charID == "DO_mgl", "Dissolved oxygen (DO)",
                                  ifelse(charID == "DO_Pct", "Dissolved oxygen saturation", "ERROR" ))),

           RsltTimeBasis = ifelse(StatisticalBasis == "7DMADMin" |
                                    StatisticalBasis == "7DMADMean" |
                                    StatisticalBasis == "7DMADMax", "7 Day",
                                  ifelse(StatisticalBasis == "30DMADMean", "30 Day", "1 Day" )),
           ActivityType = "FMC",
           Result.Analytical.Method.ID = ifelse(charID == "Conductivity", "120.1",
                                                ifelse(charID == "Dissolved oxygen (DO)", "NFM 6.2.1-LUM",
                                                       ifelse(charID == "pH","150.1",
                                                              ifelse(charID == "Temperature, water", "170.1",
                                                                     ifelse(charID == "Turbidity", "180.1",
                                                                            ifelse(charID == "Dissolved oxygen saturation", "NFM 6.2.1-LUM", "ERROR" )))))),
           SmplColMthd = "ContinuousPrb",
           SmplColEquip = "Probe/Sensor",
           SmplDepth = "",
           SmplDepthUnit = "",
           SmplColEquipComment = "",
           Samplers = "",
           # Project = Project.ID,
           AnaStartDate = "",
           AnaStartTime = "",
           AnaEndDate = "",
           AnaEndTime = "",
           ActStartDate = format(dDTmax, "%Y-%m-%d"),
           ActStartTime = "0:00",
           ActEndDate = format(dDTmax, "%Y-%m-%d"),
           ActEndTime = "23:59",
           RsltType = "Calculated",
           ActStartTimeZone = "PST",
           ActEndTimeZone = "PST",
           AnaStartTimeZone = "",
           AnaEndTimeZone = "",
           Result = round(Result, digits = 2)
    ) %>%
    dplyr::select(charID,
           Result,
           r_units,
           Result.Analytical.Method.ID,
           RsltType,
           ResultStatusID,
           StatisticalBasis,
           RsltTimeBasis,
           cmnt,
           ActivityType,
           StationCode,
           SmplColMthd,
           SmplColEquip,
           SmplDepth,
           SmplDepthUnit,
           SmplColEquipComment,
           Samplers,
           Equipment,
           #Project,
           ActStartDate,
           ActStartTime,
           ActStartTimeZone,
           ActEndDate,
           ActEndTime,
           ActEndTimeZone,
           AnaStartDate,
           AnaStartTime,
           AnaStartTimeZone,
           AnaEndDate,
           AnaEndTime,
           AnaEndTimeZone)

  openxlsx::write.xlsx(AQWMS_sum_stat, paste0(tools::file_path_sans_ext(filepath),"-statsum_4_AWQMS.xlsx"))


  # Cont. pH --------------------------------------------------------------------------------------------------------
  cont_Ph <- data_long %>%
    filter(parameter == "pH")



  cont_pH_AWQMS <- cont_Ph %>%
    dplyr::transmute('Monitoring_Location_ID' = StationCode ,
                     "Activity_start_date" = format(DateTimeStamp, "%Y/%m/%d"),
                     'Activity_Start_Time' =format(DateTimeStamp, "%H:%M:%S"),
                     'Activity_Time_Zone' = 'PST',
                     'Equipment_ID' = StationCode ,
                     'Characteristic_Name' = parameter ,
                     "Result_Value" = result,
                     "Result_Unit" = 'pH units',
                     "Result_Status_ID" = qual)


  if(nrow(cont_pH_AWQMS) > 0){
    # Export to same place as the original file
    openxlsx::write.xlsx(cont_pH_AWQMS, paste0(tools::file_path_sans_ext(filepath),"-cont_pH.xlsx"))
  }

  # Deployment info ---------------------------------------------------------

  deployments <- cont_pH_AWQMS %>%
    mutate(time_char = Activity_Start_Time,
           datetime = lubridate::ymd_hms(paste(as.Date(Activity_start_date), time_char))) %>%
    group_by(Monitoring_Location_ID, Equipment_ID ) %>%
    summarise(startdate = min(datetime),
              enddate = "",
              TZ = first(Activity_Time_Zone))

  #write.csv(deployments, paste0(tools::file_path_sans_ext(filepath),"-deployments.csv"), row.names = FALSE)

deployment_list[[h]] <- deployments

}

deplyments_all <- dplyr::bind_rows(deployment_list) |>
  group_by(Monitoring_Location_ID) |>
  arrange(startdate,.by_group = TRUE) |>
  filter(row_number()==1)

write.csv(deplyments_all, paste0(tools::file_path_sans_ext(path),"deployments.csv"), row.names = FALSE)


}
